---
title: "Taking a HINT: Leveraging Explanations to Make Vision and Language Models More Grounded"
authors:
- Ramprasaath R. Selvaraju
- Stefan Lee
- Yilin Shen
- Hongxia Jin
- Shalini Ghosh
- Larry Heck
- Dhruv Batra
- Devi Parikh
date: "2019-10-01"
publication: "ICCV"
publication_types: ["1"]
abstract: "We notice that many vision and language models suffer from poor visual grounding - often falling back on easy-to-learn language priors rather than basing their decisions on visual concepts in the image. To tackle this, we propose Human Importance-aware Network Tuning (HINT) that effectively leverages human demonstrations to improve visual grounding. We show that encouraging these models to look at same regions as humans makes them generalize to new distributions better."
featured: true
image:
  filename: hint_teaser
  focal_point: Smart
  preview_only: false
links:
- name: arXiv
  url: https://arxiv.org/abs/1902.03751
- name: Blog
  url: https://mlatgt.blog/2019/10/02/taking-a-hint-leveraging-explanations-to-make-vision-and-language-models-more-grounded/
--- 